{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras w/TF - 48s\n",
    "\n",
    "Keras w/CNTK - 75s\n",
    "\n",
    "Tensorflow - 22s\n",
    "\n",
    "MXNet - 46s\n",
    "\n",
    "PyTorch - 44s\n",
    "\n",
    "CNTK - 27s\n",
    "\n",
    "Caffe2 - 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "# Kill all GPUs ...\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "BATCH_SIZE = 128\n",
    "RESNET_FEATURES = 2048\n",
    "BATCHES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_fake_data():\n",
    "    \"\"\" Create an array of fake data to run inference on\"\"\"\n",
    "    np.random.seed(0)\n",
    "    dta = np.random.rand(BATCH_SIZE*BATCHES, 224, 224, 3).astype(np.float32)\n",
    "    return dta, np.swapaxes(dta, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create batches of fake data\n",
    "fake_input_data_cl, fake_input_data_cf = give_fake_data()\n",
    "print(fake_input_data_cl.shape, fake_input_data_cf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_mb(X, batchsize):\n",
    "    \"\"\" Function yield mini_batches of data\"\"\"\n",
    "    for i in range(len(X)//batchsize):\n",
    "        yield i, X[i*batchsize:(i+1)*batchsize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Keras defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "import keras as K\n",
    "import tensorflow as tf\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras: \", K.__version__)\n",
    "print(\"Tensorflow: \", tf.__version__)\n",
    "print(\"Keras using {}\".format(K.backend.backend()))\n",
    "print(\"Keras channel ordering is {}\".format(K.backend.image_data_format()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set channels last (default)\n",
    "K.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = classifier.predict_on_batch(dta).squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 bottom from Keras\n",
    "model = ResNet50(include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 48.7s\n",
    "# Forward-pass batches\n",
    "features = predict_fn(model, fake_input_data_cl, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras with CNTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = \"cntk\"\n",
    "import keras as K\n",
    "import cntk as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras: \", K.__version__)\n",
    "print(\"CNTK: \", C.__version__)\n",
    "print(\"Keras using {}\".format(K.backend.backend()))\n",
    "# Set channels first (default for CNTK)\n",
    "K.backend.set_image_data_format('channels_first')\n",
    "print(\"Keras channel ordering is {}\".format(K.backend.image_data_format()))\n",
    "from keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = classifier.predict_on_batch(dta).squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50 bottom from Keras\n",
    "model = ResNet50(include_top=False, input_shape=(3,224,224))\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1min15s\n",
    "features = predict_fn(model, fake_input_data_cf, BATCH_SIZE)\n",
    "print(\"No effect really when on CPU ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lots of models! (Including ResNet V2)\n",
    "# https://github.com/tensorflow/models/tree/master/research/slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "CHECKPOINT_DIR=/data/checkpoints\n",
    "mkdir ${CHECKPOINT_DIR}\n",
    "wget http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\n",
    "tar -xvf resnet_v1_50_2016_08_28.tar.gz\n",
    "mv resnet_v1_50_2016_08_28.tar.gz ${CHECKPOINT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim\n",
    "from tensorflow.contrib.slim.nets import resnet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "checkpoint_file = 'resnet_v1_50.ckpt'\n",
    "input_tensor = tf.placeholder(tf.float32, shape=(None,224,224,3), name='input_image')\n",
    "\n",
    "# Load the model\n",
    "sess = tf.Session()\n",
    "arg_scope = resnet_v1.resnet_arg_scope()\n",
    "with tensorflow.contrib.slim.arg_scope(arg_scope):\n",
    "    # Docstring ->\n",
    "    #     num_classes: Number of predicted classes for classification tasks. If None\n",
    "    #  we return the features before the logit layer.\n",
    "    logits, end_points = resnet_v1.resnet_v1_50(input_tensor, is_training=False)\n",
    "    \n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        pred = sess.run(classifier, feed_dict={input_tensor: dta}).squeeze()\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = pred\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 22.1s\n",
    "features = predict_fn(logits, fake_input_data_cl, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from collections import namedtuple\n",
    "print(\"MXNet: \", mx.__version__)\n",
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Resnet weights\n",
    "path='http://data.mxnet.io/models/imagenet/'\n",
    "[mx.test_utils.download(path+'resnet/50-layers/resnet-50-symbol.json'),\n",
    " mx.test_utils.download(path+'resnet/50-layers/resnet-50-0000.params')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)\n",
    "# List the last 10 layers\n",
    "all_layers = sym.get_internals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_layers.list_outputs()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last layer\n",
    "fe_sym = all_layers['flatten0_output']\n",
    "# Initialise\n",
    "fe_mod = mx.mod.Module(symbol=fe_sym, context=mx.cpu(), label_names=None)\n",
    "fe_mod.bind(for_training=False, data_shapes=[('data', (BATCH_SIZE,3,224,224))])\n",
    "fe_mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        classifier.forward(Batch(data=[mx.nd.array(dta)]))\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = classifier.get_outputs()[0].asnumpy().squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 46.7s\n",
    "# Forward-pass batches\n",
    "features = predict_fn(fe_mod, fake_input_data_cf, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chopped_resnet50 = torch.nn.Sequential(*list(resnet50.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    classifier.eval()\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        pred = classifier(Variable(torch.FloatTensor(dta)))\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = pred.data.numpy().squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 44.1s\n",
    "# Forward-pass batches\n",
    "features = predict_fn(chopped_resnet50, fake_input_data_cf, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CNTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cntk as C\n",
    "from cntk import load_model, combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#wget https://www.cntk.ai/Models/CNTK_Pretrained/ResNet50_ImageNet_CNTK.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (penultimate layer)\n",
    "node_name = \"z.x\"\n",
    "model_file = \"ResNet50_ImageNet_CNTK.model\"\n",
    "# Load model\n",
    "loaded_model  = load_model(model_file)\n",
    "node_in_graph = loaded_model.find_by_name(node_name)\n",
    "output_nodes  = combine([node_in_graph.owner])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        pred = classifier.eval(dta)\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = pred[0].squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 27.6s\n",
    "# Forward-pass batches\n",
    "features = predict_fn(output_nodes, fake_input_data_cf, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Caffe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import caffe2\n",
    "from caffe2.proto import caffe2_pb2\n",
    "from caffe2.python import core, workspace, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#wget https://github.com/leonardvandriel/caffe2_models/raw/master/model/resnet50_init_net.pb\n",
    "#wget https://github.com/leonardvandriel/caffe2_models/raw/master/model/resnet50_predict_net.pb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "with open(\"resnet50_init_net.pb\", \"rb\") as f:\n",
    "     init_net = f.read()\n",
    "with open(\"resnet50_predict_net.pb\", \"rb\") as f:\n",
    "    predict_net = f.read()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.RunNetOnce(init_net)\n",
    "workspace.CreateNet(predict_net)\n",
    "p = workspace.Predictor(init_net, predict_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = np.zeros((len(data), RESNET_FEATURES), np.float32)\n",
    "    for idx, dta in yield_mb(data, batchsize):\n",
    "        results = classifier.run([dta])\n",
    "        # Last feature layer should be this average-pooling\n",
    "        # I think ... \"pool5\"\n",
    "        # Still running softmax so seems wasteful\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = workspace.FetchBlob('pool5').squeeze()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 48.5s ???? Something must be wrong\n",
    "# Forward-pass batches\n",
    "features = predict_fn(p, fake_input_data_cf, BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
