{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg16, resnet50\n",
    "from keras import backend as K\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 224\n",
    "img_height = 224\n",
    "symbol = \"vgg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if symbol == \"resnet\":\n",
    "    model = resnet50.ResNet50(include_top=True, weights='imagenet')\n",
    "    print(model.summary())\n",
    "elif symbol == \"vgg\":\n",
    "    model = vgg16.VGG16(include_top=False, weights='imagenet')\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    reverse_mean = [-0.485, -0.456, -0.406]\n",
    "    reverse_std = [1/0.229, 1/0.224, 1/0.225]\n",
    "    for c in range(3):\n",
    "        x[c] /= reverse_std[c]\n",
    "        x[c] -= reverse_mean[c]\n",
    "    # Clip between 0 and 1\n",
    "    x = np.clip(x, 0, 1)\n",
    "    # Convert to RGB\n",
    "    x = np.round(x*255)\n",
    "    # Shape adj. for diff backend\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    # Convert RGB to GBR   \n",
    "    x = x[..., ::-1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(x):\n",
    "    # Expect to be numpy array between 0-1\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    # Normalize the channels\n",
    "    for channel, _ in enumerate(x):\n",
    "        x[channel] -= mean[channel]\n",
    "        x[channel] /= std[channel]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visuals_for(layer_name, layer_dict, num_to_extract=None):\n",
    "    kept_filters = []\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    num_filters = int(layer_output.shape[-1])\n",
    "    # Extract all if not specified\n",
    "    if num_to_extract is None:\n",
    "        num_to_extract = num_filters\n",
    "    # Go through filters\n",
    "    for filter_index in range(num_filters):\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "        else:\n",
    "            loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "        # Compute gradient\n",
    "        grads = K.gradients(loss, input_img)[0]\n",
    "        # Normalise grad\n",
    "        grads = normalize(grads)\n",
    "        # Return loss\n",
    "        iterate = K.function([input_img], [loss, grads])\n",
    "        # Lr for gradient ascent\n",
    "        lr = 1.\n",
    "        # Start with gray image with noise\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "        else:\n",
    "            input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "        # Process input\n",
    "        input_img_data = preprocess_image(input_img_data)\n",
    "        # Run gradient ascent\n",
    "        for i in range(50):\n",
    "            loss_value, grads_value = iterate([input_img_data])\n",
    "            input_img_data += grads_value * lr\n",
    "            if loss_value <= 0.:\n",
    "                break\n",
    "        # decode the resulting input image\n",
    "        if loss_value > 0:\n",
    "            img = deprocess_image(input_img_data[0])\n",
    "            kept_filters.append((img, loss_value))\n",
    "            print('Filter %d processed' % (filter_index))\n",
    "            if len(kept_filters) >= num_to_extract:\n",
    "                return kept_filters\n",
    "    # Extracted less than desired\n",
    "    return kept_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_filters(filter_list, num=4):\n",
    "    filter_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    return filter_list[:num * num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_filters_square(filts, n, name):\n",
    "    margin = 1\n",
    "    width = n * img_width + (n - 1) * margin\n",
    "    height = n * img_height + (n - 1) * margin\n",
    "    stitched_filters = np.zeros((width, height, 3))\n",
    "    # fill the picture with our saved filters\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            img, loss = filts[i * n + j]\n",
    "            stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                             (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "    # save the result to disk\n",
    "    imageio.imwrite('%s_%dx%d.png' % (name, n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place-holder\n",
    "input_img = model.input\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible CNN filters\n",
    "cnn_filters = [k for k, v in layer_dict.items() if \"convolutional\" in str(v)]\n",
    "print(cnn_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Layer to visualise from above\n",
    "layer_name = 'block5_conv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select how many to plot (will be square)\n",
    "plot_n = 16\n",
    "how_many_more_to_collect_before_chopping = 2  # 1, 2, or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get visualised filter maps (more than amount to plot so that can sort by loss and keep best)\n",
    "visual_filts = get_visuals_for(layer_name=layer_name, \n",
    "                               layer_dict=layer_dict,\n",
    "                               num_to_extract=how_many_more_to_collect_before_chopping*plot_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim to just best filters\n",
    "visual_filts_trim = best_filters(visual_filts, num=int(plot_n**(0.5)))\n",
    "len(visual_filts_trim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and plot square\n",
    "plot_filters_square(filts=visual_filts_trim, n=int(plot_n**(0.5)), name=layer_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
